{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e34c55-8eae-45a5-925c-7bd393f80554",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from textblob import TextBlob\n",
    "import tweepy\n",
    "import logging\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from pmdarima import auto_arima  # For auto ARIMA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Function to set up Twitter API authentication\n",
    "def initialize_twitter_api():\n",
    "    \"\"\"Initializes the Twitter API using provided credentials.\"\"\"\n",
    "    try:\n",
    "        consumer_key = \"YOUR_CONSUMER_KEY\"  # Replace with your keys\n",
    "        consumer_secret = \"YOUR_CONSUMER_SECRET\"\n",
    "        access_token = \"YOUR_ACCESS_TOKEN\"\n",
    "        access_token_secret = \"YOUR_ACCESS_TOKEN_SECRET\"\n",
    "\n",
    "        auth = tweepy.OAuth1UserHandler(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "        api = tweepy.API(auth)\n",
    "        return api\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error initializing Twitter API: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get average sentiment from tweets\n",
    "def analyze_tweet_sentiment(api, ticker, num_tweets=100):\n",
    "    \"\"\"Analyzes the sentiment of recent tweets related to a given ticker.\"\"\"\n",
    "    try:\n",
    "        if api is None:\n",
    "            return 0\n",
    "        query = f\"${ticker} OR {ticker} -filter:retweets\"  # Construct search query\n",
    "        tweets = tweepy.Cursor(api.search_tweets, q=query, lang=\"en\", tweet_mode=\"extended\", since=(datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')).items(num_tweets)\n",
    "        sentiments = []\n",
    "        for tweet in tweets:\n",
    "            try:\n",
    "                text = tweet.full_text\n",
    "                sentiment = TextBlob(text).sentiment.polarity  # Get sentiment polarity\n",
    "                sentiments.append(sentiment)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error analyzing tweet sentiment: {e}\")\n",
    "                continue\n",
    "\n",
    "        avg_sentiment = np.mean(sentiments) if sentiments else 0\n",
    "        return avg_sentiment\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching or analyzing tweets: {e}\")\n",
    "        return 0\n",
    "\n",
    "# Function to fetch historical stock data\n",
    "def fetch_historical_stock_data(ticker):\n",
    "    \"\"\"Fetches historical stock data from yfinance.\"\"\"\n",
    "    try:\n",
    "        end = datetime.now()\n",
    "        start = datetime(end.year - 5, end.month, end.day)  # Get 5 years of data\n",
    "        data = yf.download(ticker, start=start, end=end)\n",
    "        if data.empty:\n",
    "            raise ValueError(f\"No data found for ticker: {ticker}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching stock data: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to create and train ARIMA model\n",
    "def train_arima_model(train_data):\n",
    "    \"\"\"Creates and trains an ARIMA model using auto_arima for parameter selection.\"\"\"\n",
    "    try:\n",
    "        stepwise_fit = auto_arima(train_data, start_p=1, start_q=1,\n",
    "                                  max_p=5, max_q=5, m=12,  # Adjust ranges if needed\n",
    "                                  seasonal=False, trace=True,\n",
    "                                  error_action='ignore',\n",
    "                                  suppress_warnings=True,\n",
    "                                  stepwise=True)\n",
    "        print(stepwise_fit.summary())  # Print model summary\n",
    "        return stepwise_fit\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error training ARIMA model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to evaluate ARIMA model\n",
    "def evaluate_arima_predictions(model, test_data):\n",
    "    \"\"\"Evaluates the ARIMA model on test data.\"\"\"\n",
    "    try:\n",
    "        predictions = model.predict(n_periods=len(test_data))\n",
    "        rmse = math.sqrt(mean_squared_error(test_data, predictions))\n",
    "        mae = mean_absolute_error(test_data, predictions)\n",
    "        return predictions, rmse, mae\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error evaluating ARIMA model: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Function to create and train LSTM model\n",
    "def train_lstm_model(X_train, y_train):\n",
    "    \"\"\"Creates and trains an LSTM model.\"\"\"\n",
    "    try:\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(units=64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(units=64, return_sequences=True))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(LSTM(units=64))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(units=1))\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)  # Increased epochs\n",
    "        return model\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error training LSTM model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to evaluate LSTM model\n",
    "def evaluate_lstm_predictions(model, X_test, y_test):\n",
    "    \"\"\"Evaluates the LSTM model on test data.\"\"\"\n",
    "    try:\n",
    "        predictions = model.predict(X_test)\n",
    "        rmse = math.sqrt(mean_squared_error(y_test, predictions))\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        return predictions, rmse, mae\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error evaluating LSTM model: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    quote = input(\"Enter stock ticker symbol: \")\n",
    "    df = fetch_historical_stock_data(quote)\n",
    "    if df is None:\n",
    "        exit()\n",
    "    df = df.dropna()\n",
    "\n",
    "    twitter_api = initialize_twitter_api()\n",
    "    sentiment = analyze_tweet_sentiment(twitter_api, quote)\n",
    "    print(f\"Average Tweet Sentiment: {sentiment}\")\n",
    "\n",
    "    df['Sentiment'] = sentiment\n",
    "    df = df[['Close', 'Sentiment']]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    close_scaled = scaled_data[:, 0]\n",
    "\n",
    "    train_size = int(len(scaled_data) * 0.8)\n",
    "    train, test = close_scaled[:train_size], close_scaled[train_size:]\n",
    "\n",
    "    arima_model = train_arima_model(train)\n",
    "    if arima_model:\n",
    "        arima_predictions, arima_rmse, arima_mae = evaluate_arima_predictions(arima_model, test)\n",
    "        if arima_predictions is not None:\n",
    "            print(f\"ARIMA RMSE: {arima_rmse}, MAE: {arima_mae}\")\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            plt.plot(df['Close'].values[-len(test):], label='Actual Close Price')\n",
    "            plt.plot(scaler.inverse_transform(np.array(arima_predictions).reshape(-1, 1)), label='ARIMA Predictions')\n",
    "            plt.title('ARIMA Model')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "    # LSTM Model\n",
    "    X, y = [], []\n",
    "    look_back = 7\n",
    "    for i in range(look_back, len(scaled_data)):\n",
    "        X.append(scaled_data[i - look_back:i, :])\n",
    "        y.append(scaled_data[i, 0])\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False) # Shuffle set to false for time series\n",
    "\n",
    "    lstm_model = train_lstm_model(X_train, y_train)\n",
    "    if lstm_model:\n",
    "        lstm_predictions, lstm_rmse, lstm_mae = evaluate_lstm_predictions(lstm_model, X_test, y_test)\n",
    "        if lstm_predictions is not None:\n",
    "            print(f\"LSTM RMSE: {lstm_rmse}, MAE: {lstm_mae}\")\n",
    "            plt.figure(figsize=(10, 6))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
